"""
Alembic environment configuration.

This script runs during alembic operations and configures the migration environment.
"""

import os
import sys
from logging.config import fileConfig
from pathlib import Path

from alembic import context
from sqlalchemy import engine_from_config, pool

# Add the project root to Python path
sys.path.append(str(Path(__file__).resolve().parents[2]))

# ========== Import your application models and configuration ==========
# This is essential for autogenerate to work properly

# Option 1: Import SQLAlchemy Base metadata directly
try:
    from core.database import Base
    target_metadata = Base.metadata
    print("✓ Using Base.metadata from core.database")
except ImportError:
    target_metadata = None
    print("⚠️ Could not import Base.metadata, autogenerate will be limited")

# Option 2: Import all your models to ensure they're registered
try:
    # Import all models to ensure they're registered with Base.metadata
    from models.user import User, Profile
    from models.product import Product, Category # type: ignore
    from models.order import Order, OrderItem # type: ignore
    from models.system import Setting, AuditLog, RefreshToken, Country # type: ignore
    print("✓ All models imported successfully")
except ImportError as e:
    print(f"⚠️ Could not import some models: {e}")

# Option 3: Get configuration from your app settings
try:
    from core.config import settings
    DATABASE_URL = settings.DATABASE_URL
    print("✓ Using database URL from app settings")
except ImportError:
    # Fallback to environment variable or alembic.ini
    DATABASE_URL = os.getenv("DATABASE_URL")
    if not DATABASE_URL:
        DATABASE_URL = context.config.get_main_option("sqlalchemy.url")
    print("✓ Using database URL from environment/alembic.ini")

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
if config.config_file_name is not None:
    fileConfig(config.config_file_name)

# add your model's MetaData object here
# for 'autogenerate' support
# target_metadata = mymodel.Base.metadata

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def get_url():
    """Get database URL from various sources with priority."""
    # Priority 1: Command line argument
    url = context.get_x_argument(as_dictionary=True).get('db_url')
    if url:
        return url
    
    # Priority 2: Environment variable
    url = os.environ.get("DATABASE_URL")
    if url:
        return url
    
    # Priority 3: Alembic configuration
    return config.get_main_option("sqlalchemy.url")


def include_object(object, name, type_, reflected, compare_to):
    """
    Include/exclude objects in migrations.
    
    This is useful for skipping certain tables or schemas.
    """
    if type_ == "table":
        # Skip alembic_version table
        if name == "alembic_version":
            return False
        
        # Skip any table with 'tmp_' prefix
        if name.startswith('tmp_'):
            return False
        
        # Skip any table in 'archive' schema
        if hasattr(object, 'schema') and object.schema == 'archive':
            return False
    
    # Skip specific indexes if needed
    if type_ == "index" and name.startswith('idx_tmp_'):
        return False
    
    return True


def process_revision_directives(context, revision, directives):
    """Hook to modify autogenerated migration directives."""
    if config.cmd_opts is None:
        return
    
    script = directives[0]
    
    # Add header comment to migration file
    script.doc = f"""
    {revision.revision}: {revision.comment}
    
    Generated by Alembic on {revision.branch_labels}
    """
    
    # Ensure upgrade/downgrade functions have proper docstrings
    if script.upgrade_ops is not None:
        # You can modify upgrade operations here
        pass
    
    if script.downgrade_ops is not None:
        # You can modify downgrade operations here
        pass


def render_item(type_, obj, autogen_context):
    """Apply custom rendering for selected items."""
    # Custom rendering for enums
    if type_ == "type" and hasattr(obj, "create_type"):
        autogen_context.imports.add("from sqlalchemy.dialects import postgresql")
        return "postgresql.ENUM(%r, name=%r, create_type=False)" % (
            tuple(obj.enums), obj.name
        )
    
    # Default rendering
    return False


def run_migrations_offline():
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = get_url()
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        include_object=include_object,
        process_revision_directives=process_revision_directives,
        render_item=render_item,
        compare_type=True,
        compare_server_default=True,
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online():
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """
    # Get database URL
    url = get_url()
    
    # Handle SQLite special case
    if url and url.startswith('sqlite://'):
        connect_args = {"check_same_thread": False}
    else:
        connect_args = {}
    
    # Update config with URL
    config.set_main_option('sqlalchemy.url', url)
    
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
        connect_args=connect_args,
        # Additional engine options
        echo=os.getenv("SQL_ECHO", "false").lower() == "true",
        # Set isolation level for PostgreSQL
        isolation_level="READ COMMITTED" if "postgresql" in url else None,
    )

    with connectable.connect() as connection:
        # Set up context
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            include_object=include_object,
            process_revision_directives=process_revision_directives,
            render_item=render_item,
            # Migration generation options
            compare_type=True,
            compare_server_default=True,
            # For PostgreSQL specific features
            include_schemas=True if "postgresql" in url else False,
            # Transaction options
            transaction_per_migration=True,
            # Version table options
            version_table="alembic_version",
            version_table_schema=None,
            # Naming conventions (important for constraint naming)
            naming_convention={
                "ix": "ix_%(column_0_label)s",
                "uq": "uq_%(table_name)s_%(column_0_name)s",
                "ck": "ck_%(table_name)s_%(constraint_name)s",
                "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
                "pk": "pk_%(table_name)s"
            },
            # For better migration generation
            user_module_prefix=None,
        )

        # Create version table if it doesn't exist
        context.run_migrations()
        
        # Optional: Run post-migration scripts
        if context.get_x_argument(as_dictionary=True).get('run_post_migration') == 'true':
            run_post_migration_scripts(connection)


def run_post_migration_scripts(connection):
    """Run any post-migration scripts (data fixes, etc.)."""
    import sqlalchemy as sa
    
    print("Running post-migration scripts...")
    
    # Example: Ensure all existing users have profiles
    try:
        result = connection.execute(sa.text("""
            SELECT COUNT(*) 
            FROM users u 
            LEFT JOIN profiles p ON u.id = p.user_id 
            WHERE p.id IS NULL
        """))
        missing_profiles = result.scalar()
        
        if missing_profiles > 0:
            print(f"Creating missing profiles for {missing_profiles} users...")
            connection.execute(sa.text("""
                INSERT INTO profiles (user_id, created_at, updated_at)
                SELECT id, created_at, created_at
                FROM users
                WHERE id NOT IN (SELECT user_id FROM profiles)
            """))
    except Exception as e:
        print(f"Warning: Could not run profile check: {e}")


def include_name(name, type_, parent_names):
    """
    Determine whether to include a database object.
    
    This can filter by schema, table name patterns, etc.
    """
    if type_ == "schema":
        # Include all schemas except information_schema and pg_catalog
        return name not in ["information_schema", "pg_catalog"]
    
    return True


# Custom context configuration for better autogenerate
def configure_context(context):
    """Apply additional context configuration."""
    # Add custom compare functions if needed
    pass


# ========== Main execution ==========
if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()


# ========== Utility functions for migration scripts ==========
# These can be imported by migration scripts

def get_table(name, schema=None):
    """Helper to get table object in migration scripts."""
    from sqlalchemy import MetaData, Table
    metadata = MetaData()
    return Table(name, metadata, autoload_with=context.get_bind(), schema=schema)


def execute_sql(sql, params=None):
    """Helper to execute raw SQL in migration scripts."""
    connection = context.get_bind()
    return connection.execute(sql, params or {})


# ========== Migration context utilities ==========
# These are available to migration scripts via `from alembic import op`

# You can add custom operations by extending op
class CustomOperations:
    """Custom migration operations."""
    
    @staticmethod
    def create_partitioned_table(table_name, partition_key):
        """Create a partitioned table (PostgreSQL specific)."""
        # Implementation for partitioned tables
        pass
    
    @staticmethod
    def create_enum_type(type_name, values):
        """Create an enum type."""
        from sqlalchemy.dialects.postgresql import ENUM
        
        enum_type = ENUM(*values, name=type_name)
        enum_type.create(context.get_bind(), checkfirst=True)
        return enum_type


# Make custom operations available
context.custom_ops = CustomOperations()